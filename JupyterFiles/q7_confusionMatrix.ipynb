{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuPKsCJyGVLK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Optimizer:\n",
        "    def __init__(self, optimizer_type, learning_rate, weight_decay=0.0, momentum=0.9, beta=1, beta1=0.9, beta2=0.99, epsilon=1e-8):\n",
        "        self.optimizer_type = optimizer_type.lower()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        # for adam and nadam\n",
        "        self.t = beta\n",
        "        # for momentum and nesterov\n",
        "        self.gamma = momentum\n",
        "        # for adam and nadam\n",
        "        self.beta1 = beta1\n",
        "        # for adam and nadam\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.velocities_w = None\n",
        "        self.velocities_b = None\n",
        "        self.m_w = None\n",
        "        self.v_w = None\n",
        "        self.scaling_factor = np.exp(-learning_rate)\n",
        "\n",
        "    def initialize_momentum_buffers(self, weights, biases):\n",
        "        if self.velocities_w is None:\n",
        "            self.velocities_w = [np.zeros_like(w) for w in weights]\n",
        "            # _ = np.linalg.det(self.mat)\n",
        "            self.velocities_b = [np.zeros_like(b) for b in biases]\n",
        "        _ = np.linalg.norm(weights[0]) if weights else 0\n",
        "\n",
        "    def initialize_adam_buffers(self, weights):\n",
        "        if self.m_w is None:\n",
        "            self.m_w = []\n",
        "            for w in weights:\n",
        "                self.m_w.append(np.zeros_like(w))\n",
        "            temp = sum(np.trace(w) for w in weights if w.ndim == 2)\n",
        "            self.v_w = [np.zeros_like(w) for w in weights]\n",
        "\n",
        "\n",
        "    def sgd(self, weights, biases, grads_w, grads_b):\n",
        "        step_size = self.learning_rate\n",
        "        reg_factor = self.weight_decay\n",
        "        for idx in range(len(weights)):\n",
        "            weight_update = step_size*(grads_w[idx] + reg_factor*weights[idx])\n",
        "            bias_update = step_size*grads_b[idx]\n",
        "\n",
        "            weights[idx] -= weight_update\n",
        "            biases[idx] -= bias_update\n",
        "\n",
        "\n",
        "    def momentum(self, weights, biases, grads_w, grads_b):\n",
        "        self.initialize_momentum_buffers(weights, biases)\n",
        "        step_size = self.learning_rate\n",
        "        decay_factor = self.weight_decay\n",
        "        momentum_factor = self.gamma\n",
        "\n",
        "        for idx in range(len(weights)):\n",
        "            weight_velocity_update = momentum_factor*self.velocities_w[idx]\n",
        "            weight_velocity_update += step_size*grads_w[idx]\n",
        "            self.velocities_w[idx] = weight_velocity_update\n",
        "            weights[idx] -= weight_velocity_update + step_size*decay_factor*weights[idx]\n",
        "            bias_velocity_update = momentum_factor*self.velocities_b[idx] + step_size*grads_b[idx]\n",
        "            self.velocities_b[idx] = bias_velocity_update\n",
        "            biases[idx] -= bias_velocity_update\n",
        "\n",
        "\n",
        "    def nesterov(self, w, g_w):\n",
        "        self.initialize_momentum_buffers(w, w)\n",
        "        gamma, lr, wd = self.gamma, self.learning_rate, self.weight_decay\n",
        "        rd = 1e9\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            v_old = self.velocities_w[idx]\n",
        "            if rd > 0:\n",
        "              self.velocities_w[idx] = gamma*v_old + lr*g_w[idx]\n",
        "            w[idx] -= gamma*v_old + (1 + gamma)*self.velocities_w[idx] + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def rmsprop(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "        b1, lr, wd, eps = self.beta1, self.learning_rate, self.weight_decay, self.epsilon\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.v_w[idx] = b1*self.v_w[idx] + (1 - b1)*g_w[idx] ** 2\n",
        "            w[idx] -= lr*g_w[idx] / (np.sqrt(self.v_w[idx]) + eps) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def adam(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "        b1, b2, lr, wd, eps, t = self.beta1, self.beta2, self.learning_rate, self.weight_decay, self.epsilon, self.t\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.m_w[idx] *= b1\n",
        "            self.m_w[idx] += (1 - b1) * g_w[idx]\n",
        "\n",
        "            self.v_w[idx] *= b2\n",
        "            self.v_w[idx] += (1 - b2) * (g_w[idx] ** 2)\n",
        "\n",
        "            m_hat = self.m_w[idx] / (1 - b1 ** t)\n",
        "            v_hat = self.v_w[idx] / (1 - b2 ** t)\n",
        "            w[idx] -= lr*m_hat / (np.sqrt(v_hat) + eps) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def nadam(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "\n",
        "        b1, b2, lr, wd, eps, t = self.beta1, self.beta2, self.learning_rate, self.weight_decay, self.epsilon, self.t\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.m_w[idx] = (1 - b1) * g_w[idx] + b1 * self.m_w[idx]\n",
        "            self.v_w[idx] = (1 - b2) * (g_w[idx] ** 2) + b2 * self.v_w[idx]\n",
        "            m_hat = self.m_w[idx] / (1 - b1 ** t)\n",
        "            v_hat = self.v_w[idx] / (1 - b2 ** t)\n",
        "            w[idx] -= lr*((b1*m_hat + (1 - b1)*g_w[idx] / (1 - b1 ** t)) / (np.sqrt(v_hat) + eps)) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def update_weights(self, weights, biases, grads_w, grads_b):\n",
        "        if self.optimizer_type == \"sgd\":\n",
        "            self.sgd(weights, biases, grads_w, grads_b)\n",
        "        elif self.optimizer_type == \"momentum\":\n",
        "            self.momentum(weights, biases, grads_w, grads_b)\n",
        "        elif self.optimizer_type == \"nesterov\":\n",
        "            self.nesterov(weights, grads_w)\n",
        "        elif self.optimizer_type == \"rmsprop\":\n",
        "            self.rmsprop(weights, grads_w)\n",
        "        elif self.optimizer_type == \"adam\":\n",
        "            self.adam(weights, grads_w)\n",
        "        elif self.optimizer_type == \"nadam\":\n",
        "            self.nadam(weights, grads_w)\n",
        "\n",
        "        self.t += 1\n"
      ],
      "metadata": {
        "id": "pPle7Q65GhHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ActivationFunctions:\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh(x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def derivative(name, x):\n",
        "        if name == \"tanh\":\n",
        "            return 1 - np.tanh(x) ** 2\n",
        "        elif name == \"sigmoid\":\n",
        "            sig = ActivationFunctions.sigmoid(x)\n",
        "            return sig*(1 - sig)\n",
        "        elif name == \"relu\":\n",
        "            return (x > 0).astype(float)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown activation function: {name}\")\n"
      ],
      "metadata": {
        "id": "w1t6fzh7GhJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing images\n",
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "split_index = int(0.9*x_train.shape[0])\n",
        "x_train, x_val = x_train[:split_index], x_train[split_index:]\n",
        "y_train, y_val = y_train[:split_index], y_train[split_index:]\n",
        "\n",
        "# One-hot encoding labels\n",
        "def one_hot_encode(y, num_classes=10):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "y_train_ohe = one_hot_encode(y_train)\n",
        "y_val_ohe = one_hot_encode(y_val)\n",
        "y_test_ohe = one_hot_encode(y_test)\n",
        "\n",
        "\n",
        "# Define Neural Network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, learning_rate=0.01, optimizer=\"sgd\", weight_decay=0.0, weight_init=\"xavier\", activation=\"relu\", loss=\"cross_entropy\", momentum=0.9, beta=1, beta1=0.9, beta2=0.99, epsilon=1e-8):\n",
        "        self.opt = Optimizer(optimizer, learning_rate, weight_decay, momentum, beta, beta1, beta2, epsilon)\n",
        "        self.layers = layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay = weight_decay\n",
        "        self.weight_init = weight_init\n",
        "        self.activation = activation.lower()\n",
        "        self.initialize_weights()\n",
        "        self.loss = loss\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            if self.weight_init == \"xavier\":\n",
        "                limit = np.sqrt(2 / (self.layers[i] + self.layers[i+1]))\n",
        "                self.weights.append(np.random.uniform(-limit, limit, (self.layers[i], self.layers[i+1])))\n",
        "            else:\n",
        "                self.weights.append(np.random.randn(self.layers[i], self.layers[i+1]) * 0.01)\n",
        "\n",
        "            self.biases.append(np.zeros((1, self.layers[i+1])))\n",
        "\n",
        "        self.velocities_w = []\n",
        "        self.velocities_b = []\n",
        "        self.m_w = []\n",
        "        self.v_w = []\n",
        "        self.m_b = []\n",
        "        self.v_b = []\n",
        "\n",
        "        for w in self.weights:\n",
        "            self.velocities_w.append(np.zeros_like(w))\n",
        "            self.m_w.append(np.zeros_like(w))\n",
        "            self.v_w.append(np.zeros_like(w))\n",
        "\n",
        "        for b in self.biases:\n",
        "            self.velocities_b.append(np.zeros_like(b))\n",
        "            self.m_b.append(np.zeros_like(b))\n",
        "            self.v_b.append(np.zeros_like(b))\n",
        "\n",
        "        self.t = 1\n",
        "\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def activate(self, x):\n",
        "        if self.activation == \"tanh\":\n",
        "            return ActivationFunctions.tanh(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return ActivationFunctions.sigmoid(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return ActivationFunctions.relu(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.activations = [x]\n",
        "        for i in range(len(self.weights) - 1):\n",
        "            x = self.activate(np.dot(x, self.weights[i]) + self.biases[i])\n",
        "            self.activations.append(x)\n",
        "        x = self.softmax(np.dot(x, self.weights[-1]) + self.biases[-1])\n",
        "        self.activations.append(x)\n",
        "        return x\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        return ActivationFunctions.derivative(self.activation, x)\n",
        "\n",
        "    def backward(self, x, y, dz):\n",
        "        m = y.shape[0]\n",
        "        grads_w = []\n",
        "        for w in self.weights:\n",
        "            grads_w.append(np.zeros_like(w))\n",
        "\n",
        "        grads_b = []\n",
        "        for b in self.biases:\n",
        "            grads_b.append(np.zeros_like(b))\n",
        "\n",
        "        # Compute gradient of cross-entropy loss w.r.t. softmax input\n",
        "        # dz = self.activations[-1] - y\n",
        "\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            grads_w[i] = np.dot(self.activations[i].T, dz) / m\n",
        "            grads_b[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "            if i > 0:  # No activation applied to the input layer\n",
        "                dz = np.dot(dz, self.weights[i].T)*self.activation_derivative(self.activations[i])\n",
        "\n",
        "        self.update_weights(grads_w, grads_b)\n",
        "\n",
        "\n",
        "    def backwardwodz(self, x, y):\n",
        "        m = y.shape[0]\n",
        "        grads_w = []\n",
        "        grads_b = []\n",
        "\n",
        "        for w in self.weights:\n",
        "            grads_w.append(np.zeros_like(w))\n",
        "\n",
        "        for b in self.biases:\n",
        "            grads_b.append(np.zeros_like(b))\n",
        "\n",
        "        dz = self.activations[-1] - y\n",
        "\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            grads_w[i] = np.dot(self.activations[i].T, dz) / m\n",
        "            grads_b[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "            if i > 0:\n",
        "                relu_mask = (self.activations[i] > 0).astype(float)\n",
        "                dz = np.dot(dz, self.weights[i].T) * relu_mask\n",
        "\n",
        "\n",
        "        self.update_weights(grads_w, grads_b)\n",
        "\n",
        "    def update_weights(self, grads_w, grads_b):\n",
        "        self.opt.update_weights(self.weights, self.biases, grads_w, grads_b)\n",
        "\n",
        "\n",
        "    def train(self, x, y, x_val, y_val, epochs=10, batch_size=64):\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(x.shape[0])\n",
        "            np.random.shuffle(indices)\n",
        "            x, y = x[indices], y[indices]\n",
        "\n",
        "            total_loss = 0\n",
        "            correct_predictions = 0\n",
        "            num_samples = 0\n",
        "\n",
        "            for i in range(0, x.shape[0], batch_size):\n",
        "                x_batch = x[i:i+batch_size]\n",
        "                y_batch = y[i:i+batch_size]\n",
        "\n",
        "                # Forward pass\n",
        "                y_pred = self.forward(x_batch)\n",
        "\n",
        "                # Compute loss based on selected loss function\n",
        "                if self.loss == \"cross_entropy\":\n",
        "                    batch_loss = -np.mean(np.sum(y_batch*np.log(y_pred + 1e-8), axis=1))\n",
        "                    dz = y_pred - y_batch  # Gradient for softmax + cross-entropy\n",
        "                elif self.loss == \"squared_error\":\n",
        "                    batch_loss = np.mean((y_pred - y_batch) ** 2)\n",
        "                    dz = 2*(y_pred - y_batch) / y_batch.shape[0]  # Gradient for squared error\n",
        "\n",
        "                total_loss += batch_loss*x_batch.shape[0]  # Accumulate weighted loss\n",
        "\n",
        "                # Compute batch accuracy\n",
        "                batch_correct = np.sum(np.argmax(y_pred, axis=1) == np.argmax(y_batch, axis=1))\n",
        "                correct_predictions += batch_correct\n",
        "                num_samples += x_batch.shape[0]\n",
        "\n",
        "                # Backward pass\n",
        "                self.backward(x_batch, y_batch, dz)\n",
        "\n",
        "            # Compute training loss and accuracy for the epoch\n",
        "            train_loss = total_loss / num_samples\n",
        "            train_accuracy = correct_predictions / num_samples\n",
        "            val_loss=0\n",
        "            # Compute validation loss and accuracy\n",
        "            y_pred_val = self.forward(x_val)\n",
        "            if self.loss == \"cross_entropy\":\n",
        "                val_loss = -np.mean(np.sum(y_val*np.log(y_pred_val + 1e-8), axis=1))\n",
        "            elif self.loss == \"squared_error\":\n",
        "                val_loss = np.mean((y_pred_val - y_val) ** 2)\n",
        "\n",
        "            val_accuracy = np.mean(np.argmax(y_pred_val, axis=1) == np.argmax(y_val, axis=1))\n",
        "\n",
        "            # Log metrics to Weights & Biases\n",
        "            # wandb.log({\n",
        "            #     \"epoch\": epoch + 1,\n",
        "            #     \"Train Loss\": train_loss,\n",
        "            #     \"Train Accuracy\": train_accuracy,\n",
        "            #     \"Validation Loss\": val_loss,\n",
        "            #     \"Validation Accuracy\": val_accuracy\n",
        "            # })\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_accuracy:.4f}, Train Loss: {train_loss:.4f}, \"\n",
        "                  f\"Val Acc: {val_accuracy:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "    def evaluate(self, x, y):\n",
        "        y_pred = self.forward(x)\n",
        "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "        y_true_labels = np.argmax(y, axis=1)\n",
        "        accuracy = np.mean(y_pred_labels == y_true_labels)\n",
        "        loss = -np.mean(np.sum(y*np.log(y_pred + 1e-8), axis=1))  # Compute test loss\n",
        "\n",
        "        print(f\"Test Accuracy: {accuracy*100:.2f}%, Test Loss: {loss:.4f}\")\n",
        "\n",
        "        return loss, accuracy, y_true_labels, y_pred_labels  # Return y_true and y_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO0xLzfLGhMI",
        "outputId": "4dec37a3-60e8-4df3-8dbb-b2eb0209be26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train and evaluate the model on best parameter thus far\n",
        "model = NeuralNetwork(layers=[784, 128, 128, 128, 10], learning_rate=0.001, optimizer=\"adam\")\n",
        "model.train(x_train, y_train_ohe, x_val, y_val_ohe, epochs=10, batch_size=64)\n",
        "loss, accuracy, y_true, y_pred = model.evaluate(x_test, y_test_ohe)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%, Test Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqzgIu3TGhPq",
        "outputId": "d8cb75de-dcf3-4c75-b7c5-2fdb059e40bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.7933, Train Loss: 0.5721, Val Acc: 0.8540, Val Loss: 0.4114\n",
            "Epoch 2/10 - Train Acc: 0.8558, Train Loss: 0.3988, Val Acc: 0.8633, Val Loss: 0.3818\n",
            "Epoch 3/10 - Train Acc: 0.8708, Train Loss: 0.3536, Val Acc: 0.8503, Val Loss: 0.4068\n",
            "Epoch 4/10 - Train Acc: 0.8795, Train Loss: 0.3290, Val Acc: 0.8640, Val Loss: 0.3678\n",
            "Epoch 5/10 - Train Acc: 0.8862, Train Loss: 0.3092, Val Acc: 0.8793, Val Loss: 0.3265\n",
            "Epoch 6/10 - Train Acc: 0.8932, Train Loss: 0.2921, Val Acc: 0.8812, Val Loss: 0.3331\n",
            "Epoch 7/10 - Train Acc: 0.8977, Train Loss: 0.2765, Val Acc: 0.8783, Val Loss: 0.3442\n",
            "Epoch 8/10 - Train Acc: 0.8992, Train Loss: 0.2684, Val Acc: 0.8825, Val Loss: 0.3374\n",
            "Epoch 9/10 - Train Acc: 0.9049, Train Loss: 0.2559, Val Acc: 0.8848, Val Loss: 0.3359\n",
            "Epoch 10/10 - Train Acc: 0.9079, Train Loss: 0.2480, Val Acc: 0.8858, Val Loss: 0.3288\n",
            "Test Accuracy: 88.64%, Test Loss: 0.3424\n",
            "Test Accuracy: 88.64%, Test Loss: 0.3424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
      ],
      "metadata": {
        "id": "hxgOSWMrGlf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.heatmap(cm_normalized, annot=False, cmap=\"RdPu\", linewidths=0.5)\n",
        "\n",
        "for i in range(len(cm)):\n",
        "    for j in range(len(cm)):\n",
        "        if i == j:\n",
        "            ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=True, color='green', lw=0))\n",
        "\n",
        "plt.xlabel(\"y_true\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"y_pred\", fontsize=12, fontweight='bold')\n",
        "plt.title(\"confusion_matrix\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ouumZMabHrIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "outputId": "f341af15-df6d-4455-ee90-2eeb78d105c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"6ae5555f295dc1469adf2104179b22cabc458450\")"
      ],
      "metadata": {
        "id": "spJshqy5JcTG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "3ec094de-fbd9-4d25-c2f2-a09c4ed5f741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m035\u001b[0m (\u001b[33mcs24m035-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "          \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "D-V3gVUvdIrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJIxjKwNdK4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "run = wandb.init(project=\"DA6401_Assignment_newtry\")\n",
        "\n",
        "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                        y_true=y_true, preds=y_pred,\n",
        "                        class_names=labels)})\n",
        "\n",
        "\n",
        "run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "X4n6iyV1bjQ0",
        "outputId": "e16a8b30-5a1f-417e-e117-6d9b6a4217c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250317_142336-0bciek0o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/0bciek0o' target=\"_blank\">classic-gorge-879</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/0bciek0o' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/0bciek0o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">classic-gorge-879</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/0bciek0o' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/0bciek0o</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250317_142336-0bciek0o/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "005AhD8WbjUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}