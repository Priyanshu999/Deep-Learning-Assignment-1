{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zuPKsCJyGVLK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Optimizer:\n",
        "    def __init__(self, optimizer_type, learning_rate, weight_decay=0.0, momentum=0.9, beta=1, beta1=0.9, beta2=0.99, epsilon=1e-8):\n",
        "        self.optimizer_type = optimizer_type.lower()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        # for adam and nadam\n",
        "        self.t = beta\n",
        "        # for momentum and nesterov\n",
        "        self.gamma = momentum\n",
        "        # for adam and nadam\n",
        "        self.beta1 = beta1\n",
        "        # for adam and nadam\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.velocities_w = None\n",
        "        self.velocities_b = None\n",
        "        self.m_w = None\n",
        "        self.v_w = None\n",
        "        self.scaling_factor = np.exp(-learning_rate)\n",
        "\n",
        "    def initialize_momentum_buffers(self, weights, biases):\n",
        "        if self.velocities_w is None:\n",
        "            self.velocities_w = [np.zeros_like(w) for w in weights]\n",
        "            # _ = np.linalg.det(self.mat)\n",
        "            self.velocities_b = [np.zeros_like(b) for b in biases]\n",
        "        _ = np.linalg.norm(weights[0]) if weights else 0\n",
        "\n",
        "    def initialize_adam_buffers(self, weights):\n",
        "        if self.m_w is None:\n",
        "            self.m_w = []\n",
        "            for w in weights:\n",
        "                self.m_w.append(np.zeros_like(w))\n",
        "            temp = sum(np.trace(w) for w in weights if w.ndim == 2)\n",
        "            self.v_w = [np.zeros_like(w) for w in weights]\n",
        "\n",
        "\n",
        "    def sgd(self, weights, biases, grads_w, grads_b):\n",
        "        step_size = self.learning_rate\n",
        "        reg_factor = self.weight_decay\n",
        "        for idx in range(len(weights)):\n",
        "            weight_update = step_size*(grads_w[idx] + reg_factor*weights[idx])\n",
        "            bias_update = step_size*grads_b[idx]\n",
        "\n",
        "            weights[idx] -= weight_update\n",
        "            biases[idx] -= bias_update\n",
        "\n",
        "\n",
        "    def momentum(self, weights, biases, grads_w, grads_b):\n",
        "        self.initialize_momentum_buffers(weights, biases)\n",
        "        step_size = self.learning_rate\n",
        "        decay_factor = self.weight_decay\n",
        "        momentum_factor = self.gamma\n",
        "\n",
        "        for idx in range(len(weights)):\n",
        "            weight_velocity_update = momentum_factor*self.velocities_w[idx]\n",
        "            weight_velocity_update += step_size*grads_w[idx]\n",
        "            self.velocities_w[idx] = weight_velocity_update\n",
        "            weights[idx] -= weight_velocity_update + step_size*decay_factor*weights[idx]\n",
        "            bias_velocity_update = momentum_factor*self.velocities_b[idx] + step_size*grads_b[idx]\n",
        "            self.velocities_b[idx] = bias_velocity_update\n",
        "            biases[idx] -= bias_velocity_update\n",
        "\n",
        "\n",
        "    def nesterov(self, w, g_w):\n",
        "        self.initialize_momentum_buffers(w, w)\n",
        "        gamma, lr, wd = self.gamma, self.learning_rate, self.weight_decay\n",
        "        rd = 1e9\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            v_old = self.velocities_w[idx]\n",
        "            if rd > 0:\n",
        "              self.velocities_w[idx] = gamma*v_old + lr*g_w[idx]\n",
        "            w[idx] -= gamma*v_old + (1 + gamma)*self.velocities_w[idx] + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def rmsprop(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "        b1, lr, wd, eps = self.beta1, self.learning_rate, self.weight_decay, self.epsilon\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.v_w[idx] = b1*self.v_w[idx] + (1 - b1)*g_w[idx] ** 2\n",
        "            w[idx] -= lr*g_w[idx] / (np.sqrt(self.v_w[idx]) + eps) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def adam(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "        b1, b2, lr, wd, eps, t = self.beta1, self.beta2, self.learning_rate, self.weight_decay, self.epsilon, self.t\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.m_w[idx] *= b1\n",
        "            self.m_w[idx] += (1 - b1) * g_w[idx]\n",
        "\n",
        "            self.v_w[idx] *= b2\n",
        "            self.v_w[idx] += (1 - b2) * (g_w[idx] ** 2)\n",
        "\n",
        "            m_hat = self.m_w[idx] / (1 - b1 ** t)\n",
        "            v_hat = self.v_w[idx] / (1 - b2 ** t)\n",
        "            w[idx] -= lr*m_hat / (np.sqrt(v_hat) + eps) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def nadam(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "\n",
        "        b1, b2, lr, wd, eps, t = self.beta1, self.beta2, self.learning_rate, self.weight_decay, self.epsilon, self.t\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.m_w[idx] = (1 - b1) * g_w[idx] + b1 * self.m_w[idx]\n",
        "            self.v_w[idx] = (1 - b2) * (g_w[idx] ** 2) + b2 * self.v_w[idx]\n",
        "            m_hat = self.m_w[idx] / (1 - b1 ** t)\n",
        "            v_hat = self.v_w[idx] / (1 - b2 ** t)\n",
        "            w[idx] -= lr*((b1*m_hat + (1 - b1)*g_w[idx] / (1 - b1 ** t)) / (np.sqrt(v_hat) + eps)) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def update_weights(self, weights, biases, grads_w, grads_b):\n",
        "        if self.optimizer_type == \"sgd\":\n",
        "            self.sgd(weights, biases, grads_w, grads_b)\n",
        "        elif self.optimizer_type == \"momentum\":\n",
        "            self.momentum(weights, biases, grads_w, grads_b)\n",
        "        elif self.optimizer_type == \"nesterov\":\n",
        "            self.nesterov(weights, grads_w)\n",
        "        elif self.optimizer_type == \"rmsprop\":\n",
        "            self.rmsprop(weights, grads_w)\n",
        "        elif self.optimizer_type == \"adam\":\n",
        "            self.adam(weights, grads_w)\n",
        "        elif self.optimizer_type == \"nadam\":\n",
        "            self.nadam(weights, grads_w)\n",
        "\n",
        "        self.t += 1\n"
      ],
      "metadata": {
        "id": "pPle7Q65GhHn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ActivationFunctions:\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh(x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def derivative(name, x):\n",
        "        if name == \"tanh\":\n",
        "            return 1 - np.tanh(x) ** 2\n",
        "        elif name == \"sigmoid\":\n",
        "            sig = ActivationFunctions.sigmoid(x)\n",
        "            return sig*(1 - sig)\n",
        "        elif name == \"relu\":\n",
        "            return (x > 0).astype(float)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown activation function: {name}\")\n"
      ],
      "metadata": {
        "id": "w1t6fzh7GhJ-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing images\n",
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "split_index = int(0.9*x_train.shape[0])\n",
        "x_train, x_val = x_train[:split_index], x_train[split_index:]\n",
        "y_train, y_val = y_train[:split_index], y_train[split_index:]\n",
        "\n",
        "# One-hot encoding labels\n",
        "def one_hot_encode(y, num_classes=10):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "y_train_ohe = one_hot_encode(y_train)\n",
        "y_val_ohe = one_hot_encode(y_val)\n",
        "y_test_ohe = one_hot_encode(y_test)\n",
        "\n",
        "\n",
        "# Define Neural Network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, learning_rate=0.01, optimizer=\"sgd\", weight_decay=0.0, weight_init=\"random\", activation=\"relu\", loss=\"cross_entropy\", momentum=0.9, beta=1, beta1=0.9, beta2=0.99, epsilon=1e-8):\n",
        "        self.opt = Optimizer(optimizer, learning_rate, weight_decay, momentum, beta, beta1, beta2, epsilon)\n",
        "        self.layers = layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay = weight_decay\n",
        "        self.weight_init = weight_init\n",
        "        self.activation = activation.lower()\n",
        "        self.initialize_weights()\n",
        "        self.loss = loss\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            if self.weight_init == \"xavier\":\n",
        "                limit = np.sqrt(2 / (self.layers[i] + self.layers[i+1]))\n",
        "                self.weights.append(np.random.uniform(-limit, limit, (self.layers[i], self.layers[i+1])))\n",
        "            else:\n",
        "                self.weights.append(np.random.randn(self.layers[i], self.layers[i+1]) * 0.01)\n",
        "\n",
        "            self.biases.append(np.zeros((1, self.layers[i+1])))\n",
        "\n",
        "        self.velocities_w = []\n",
        "        self.velocities_b = []\n",
        "        self.m_w = []\n",
        "        self.v_w = []\n",
        "        self.m_b = []\n",
        "        self.v_b = []\n",
        "\n",
        "        for w in self.weights:\n",
        "            self.velocities_w.append(np.zeros_like(w))\n",
        "            self.m_w.append(np.zeros_like(w))\n",
        "            self.v_w.append(np.zeros_like(w))\n",
        "\n",
        "        for b in self.biases:\n",
        "            self.velocities_b.append(np.zeros_like(b))\n",
        "            self.m_b.append(np.zeros_like(b))\n",
        "            self.v_b.append(np.zeros_like(b))\n",
        "\n",
        "        self.t = 1\n",
        "\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def activate(self, x):\n",
        "        if self.activation == \"tanh\":\n",
        "            return ActivationFunctions.tanh(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return ActivationFunctions.sigmoid(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return ActivationFunctions.relu(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.activations = [x]\n",
        "        for i in range(len(self.weights) - 1):\n",
        "            x = self.activate(np.dot(x, self.weights[i]) + self.biases[i])\n",
        "            self.activations.append(x)\n",
        "        x = self.softmax(np.dot(x, self.weights[-1]) + self.biases[-1])\n",
        "        self.activations.append(x)\n",
        "        return x\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        return ActivationFunctions.derivative(self.activation, x)\n",
        "\n",
        "    def backward(self, x, y, dz):\n",
        "        m = y.shape[0]\n",
        "        grads_w = []\n",
        "        for w in self.weights:\n",
        "            grads_w.append(np.zeros_like(w))\n",
        "\n",
        "        grads_b = []\n",
        "        for b in self.biases:\n",
        "            grads_b.append(np.zeros_like(b))\n",
        "\n",
        "        # Compute gradient of cross-entropy loss w.r.t. softmax input\n",
        "        # dz = self.activations[-1] - y\n",
        "\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            grads_w[i] = np.dot(self.activations[i].T, dz) / m\n",
        "            grads_b[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "            if i > 0:  # No activation applied to the input layer\n",
        "                dz = np.dot(dz, self.weights[i].T)*self.activation_derivative(self.activations[i])\n",
        "\n",
        "        self.update_weights(grads_w, grads_b)\n",
        "\n",
        "\n",
        "    def backwardwodz(self, x, y):\n",
        "        m = y.shape[0]\n",
        "        grads_w = []\n",
        "        grads_b = []\n",
        "\n",
        "        for w in self.weights:\n",
        "            grads_w.append(np.zeros_like(w))\n",
        "\n",
        "        for b in self.biases:\n",
        "            grads_b.append(np.zeros_like(b))\n",
        "\n",
        "        dz = self.activations[-1] - y\n",
        "\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            grads_w[i] = np.dot(self.activations[i].T, dz) / m\n",
        "            grads_b[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "            if i > 0:\n",
        "                relu_mask = (self.activations[i] > 0).astype(float)\n",
        "                dz = np.dot(dz, self.weights[i].T) * relu_mask\n",
        "\n",
        "\n",
        "        self.update_weights(grads_w, grads_b)\n",
        "\n",
        "    def update_weights(self, grads_w, grads_b):\n",
        "        self.opt.update_weights(self.weights, self.biases, grads_w, grads_b)\n",
        "\n",
        "\n",
        "    def train(self, x, y, x_val, y_val, epochs=10, batch_size=64):\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(x.shape[0])\n",
        "            np.random.shuffle(indices)\n",
        "            x, y = x[indices], y[indices]\n",
        "\n",
        "            total_loss = 0\n",
        "            correct_predictions = 0\n",
        "            num_samples = 0\n",
        "\n",
        "            for i in range(0, x.shape[0], batch_size):\n",
        "                x_batch = x[i:i+batch_size]\n",
        "                y_batch = y[i:i+batch_size]\n",
        "\n",
        "                # Forward pass\n",
        "                y_pred = self.forward(x_batch)\n",
        "\n",
        "                # Compute loss based on selected loss function\n",
        "                if self.loss == \"cross_entropy\":\n",
        "                    batch_loss = -np.mean(np.sum(y_batch*np.log(y_pred + 1e-8), axis=1))\n",
        "                    dz = y_pred - y_batch  # Gradient for softmax + cross-entropy\n",
        "                elif self.loss == \"squared_error\":\n",
        "                    batch_loss = np.mean((y_pred - y_batch) ** 2)\n",
        "                    dz = 2*(y_pred - y_batch) / y_batch.shape[0]  # Gradient for squared error\n",
        "\n",
        "                total_loss += batch_loss*x_batch.shape[0]  # Accumulate weighted loss\n",
        "\n",
        "                # Compute batch accuracy\n",
        "                batch_correct = np.sum(np.argmax(y_pred, axis=1) == np.argmax(y_batch, axis=1))\n",
        "                correct_predictions += batch_correct\n",
        "                num_samples += x_batch.shape[0]\n",
        "\n",
        "                # Backward pass\n",
        "                self.backward(x_batch, y_batch, dz)\n",
        "\n",
        "            # Compute training loss and accuracy for the epoch\n",
        "            train_loss = total_loss / num_samples\n",
        "            train_accuracy = correct_predictions / num_samples\n",
        "            val_loss=0\n",
        "            # Compute validation loss and accuracy\n",
        "            y_pred_val = self.forward(x_val)\n",
        "            if self.loss == \"cross_entropy\":\n",
        "                val_loss = -np.mean(np.sum(y_val*np.log(y_pred_val + 1e-8), axis=1))\n",
        "            elif self.loss == \"squared_error\":\n",
        "                val_loss = np.mean((y_pred_val - y_val) ** 2)\n",
        "\n",
        "            val_accuracy = np.mean(np.argmax(y_pred_val, axis=1) == np.argmax(y_val, axis=1))\n",
        "\n",
        "            Log metrics to Weights & Biases\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"Train Loss\": train_loss,\n",
        "                \"Train Accuracy\": train_accuracy,\n",
        "                \"Validation Loss\": val_loss,\n",
        "                \"Validation Accuracy\": val_accuracy\n",
        "            })\n",
        "\n",
        "            Print metrics\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_accuracy:.4f}, Train Loss: {train_loss:.4f}, \"\n",
        "                  f\"Val Acc: {val_accuracy:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "    def evaluate(self, x, y):\n",
        "        y_pred = self.forward(x)\n",
        "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "        y_true_labels = np.argmax(y, axis=1)\n",
        "        accuracy = np.mean(y_pred_labels == y_true_labels)\n",
        "        loss = -np.mean(np.sum(y*np.log(y_pred + 1e-8), axis=1))  # Compute test loss\n",
        "\n",
        "        print(f\"Test Accuracy: {accuracy*100:.2f}%, Test Loss: {loss:.4f}\")\n",
        "\n",
        "        return loss, accuracy, y_true_labels, y_pred_labels  # Return y_true and y_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO0xLzfLGhMI",
        "outputId": "45a05987-c2a7-428c-8c7a-e36c58fc772e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the model\n",
        "model = NeuralNetwork(layers=[784, 128, 128, 128, 10], learning_rate=0.005, optimizer=\"nesterov\")\n",
        "model.train(x_train, y_train_ohe, x_val, y_val_ohe, epochs=5, batch_size=64)\n",
        "loss, accuracy, y_true, y_pred = model.evaluate(x_test, y_test_ohe)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%, Test Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqzgIu3TGhPq",
        "outputId": "3dc5c82d-090f-48eb-b2e1-369471dfc0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Acc: 0.2214, Train Loss: 2.2923, Val Acc: 0.2193, Val Loss: 1.7990\n",
            "Epoch 2/5 - Train Acc: 0.5438, Train Loss: 1.0687, Val Acc: 0.7137, Val Loss: 0.7269\n",
            "Epoch 3/5 - Train Acc: 0.7558, Train Loss: 0.6419, Val Acc: 0.8038, Val Loss: 0.5251\n",
            "Epoch 4/5 - Train Acc: 0.8290, Train Loss: 0.4795, Val Acc: 0.8345, Val Loss: 0.4545\n",
            "Epoch 5/5 - Train Acc: 0.8488, Train Loss: 0.4186, Val Acc: 0.8380, Val Loss: 0.4549\n",
            "Test Accuracy: 82.16%, Test Loss: 0.4838\n",
            "Test Accuracy: 82.16%, Test Loss: 0.4838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "5DZ_BZMiHdiM",
        "outputId": "5848e043-c95b-4922-f301-c2a65499a4eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m035\u001b[0m (\u001b[33mcs24m035-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sweep(losse):\n",
        "    run = wandb.init()\n",
        "    config = wandb.config\n",
        "\n",
        "    # Generate a custom run name\n",
        "    run_name = f\"hl_{config.hidden_layers}_bs_{config.batch_size}_ac_{config.activation}_ls_{losse}_lr_{config.learning_rate}_opt_{config.optimizer}_init_{config.weight_init}\"\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "\n",
        "    loss_function = losse\n",
        "\n",
        "    model = NeuralNetwork(\n",
        "        layers=[784] + [config.layer_size]*config.hidden_layers + [10],\n",
        "        learning_rate=config.learning_rate,\n",
        "        optimizer=config.optimizer,\n",
        "        weight_decay=config.weight_decay,\n",
        "        weight_init=config.weight_init,\n",
        "        activation=config.activation,\n",
        "        loss=loss_function\n",
        "    )\n",
        "    model.train(x_train, y_train_ohe, x_val, y_val_ohe, epochs=config.epochs, batch_size=config.batch_size)\n",
        "\n",
        "    test_loss, test_accuracy, y_true, y_pred = model.evaluate(x_test, y_test_ohe)\n",
        "\n",
        "    # Log final test metrics\n",
        "    wandb.log({\"Test Loss\": test_loss, \"Test Accuracy\": test_accuracy})\n",
        "\n",
        "    print(f\"Final Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    run.finish()\n"
      ],
      "metadata": {
        "id": "hxgOSWMrGlf-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"Test Accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [5, 10]},\n",
        "        \"hidden_layers\": {\"values\": [3, 4, 5]},\n",
        "        \"layer_size\": {\"values\": [32, 64, 128]},\n",
        "        \"weight_decay\": {\"values\": [0, 0.0005, 0.5]},\n",
        "        \"learning_rate\": {\"values\": [1e-3, 1e-4]},\n",
        "        \"optimizer\": {\"values\": [\"sgd\", \"momentum\", \"nesterov\", \"rmsprop\", \"adam\", \"nadam\"]},\n",
        "        \"batch_size\": {\"values\": [16, 32, 64]},\n",
        "        \"weight_init\": {\"values\": [\"random\", \"xavier\"]},\n",
        "        \"activation\": {\"values\": [\"sigmoid\", \"tanh\", \"relu\"]}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"JustAnotherTesting\")\n",
        "wandb.agent(sweep_id, function=lambda: train_sweep(\"cross_entropy\"), count=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KktRkBaEHm0z",
        "outputId": "e8f0284f-0324-4025-9891-6fcc9c43e281"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 0zk0wvvn\n",
            "Sweep URL: https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 73gk0mki with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_180215-73gk0mki</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/73gk0mki' target=\"_blank\">prime-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/73gk0mki' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/73gk0mki</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Acc: 0.3696, Train Loss: 1.4941, Val Acc: 0.5190, Val Loss: 1.0966\n",
            "Epoch 2/5 - Train Acc: 0.5287, Train Loss: 1.0532, Val Acc: 0.5312, Val Loss: 1.0224\n",
            "Epoch 3/5 - Train Acc: 0.5475, Train Loss: 1.0164, Val Acc: 0.5557, Val Loss: 0.9980\n",
            "Epoch 4/5 - Train Acc: 0.5628, Train Loss: 0.9990, Val Acc: 0.5835, Val Loss: 0.9852\n",
            "Epoch 5/5 - Train Acc: 0.5710, Train Loss: 0.9868, Val Acc: 0.5828, Val Loss: 0.9790\n",
            "Test Accuracy: 57.01%, Test Loss: 0.9926\n",
            "Final Test Accuracy: 0.5701, Test Loss: 0.9926\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.5701</td></tr><tr><td>Test Loss</td><td>0.99256</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_4_bs_32_ac_relu_ls_cross_entropy_lr_0.0001_opt_nadam_init_random</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/73gk0mki' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/73gk0mki</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_180215-73gk0mki/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wzi9116z with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_180241-wzi9116z</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/wzi9116z' target=\"_blank\">quiet-sweep-2</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/wzi9116z' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/wzi9116z</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Acc: 0.2144, Train Loss: 2.2815, Val Acc: 0.3247, Val Loss: 2.2553\n",
            "Epoch 2/5 - Train Acc: 0.2999, Train Loss: 2.1762, Val Acc: 0.2787, Val Loss: 2.0419\n",
            "Epoch 3/5 - Train Acc: 0.2794, Train Loss: 1.8689, Val Acc: 0.2290, Val Loss: 1.7523\n",
            "Epoch 4/5 - Train Acc: 0.2609, Train Loss: 1.6902, Val Acc: 0.3212, Val Loss: 1.6362\n",
            "Epoch 5/5 - Train Acc: 0.3569, Train Loss: 1.5744, Val Acc: 0.4488, Val Loss: 1.5073\n",
            "Test Accuracy: 44.35%, Test Loss: 1.5129\n",
            "Final Test Accuracy: 0.4435, Test Loss: 1.5129\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.4435</td></tr><tr><td>Test Loss</td><td>1.51291</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_5_bs_32_ac_tanh_ls_cross_entropy_lr_0.001_opt_sgd_init_xavier</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/wzi9116z' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/wzi9116z</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_180241-wzi9116z/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: im66x7yx with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nesterov\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_180311-im66x7yx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/im66x7yx' target=\"_blank\">graceful-sweep-3</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/im66x7yx' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/im66x7yx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.0989, Train Loss: 2.3061, Val Acc: 0.0985, Val Loss: 2.3045\n",
            "Epoch 2/10 - Train Acc: 0.1010, Train Loss: 2.3035, Val Acc: 0.1003, Val Loss: 2.3037\n",
            "Epoch 3/10 - Train Acc: 0.0994, Train Loss: 2.3035, Val Acc: 0.0925, Val Loss: 2.3031\n",
            "Epoch 4/10 - Train Acc: 0.0983, Train Loss: 2.3035, Val Acc: 0.1032, Val Loss: 2.3025\n",
            "Epoch 5/10 - Train Acc: 0.1000, Train Loss: 2.3034, Val Acc: 0.1008, Val Loss: 2.3037\n",
            "Epoch 6/10 - Train Acc: 0.0993, Train Loss: 2.3035, Val Acc: 0.0973, Val Loss: 2.3034\n",
            "Epoch 7/10 - Train Acc: 0.0976, Train Loss: 2.3035, Val Acc: 0.0942, Val Loss: 2.3032\n",
            "Epoch 8/10 - Train Acc: 0.0978, Train Loss: 2.3034, Val Acc: 0.1050, Val Loss: 2.3029\n",
            "Epoch 9/10 - Train Acc: 0.0980, Train Loss: 2.3035, Val Acc: 0.0985, Val Loss: 2.3040\n",
            "Epoch 10/10 - Train Acc: 0.1015, Train Loss: 2.3034, Val Acc: 0.0925, Val Loss: 2.3036\n",
            "Test Accuracy: 10.00%, Test Loss: 2.3033\n",
            "Final Test Accuracy: 0.1000, Test Loss: 2.3033\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.1</td></tr><tr><td>Test Loss</td><td>2.30325</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_5_bs_64_ac_sigmoid_ls_cross_entropy_lr_0.001_opt_nesterov_init_xavier</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/im66x7yx' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/im66x7yx</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_180311-im66x7yx/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 410k9baw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_180353-410k9baw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/410k9baw' target=\"_blank\">stellar-sweep-4</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/410k9baw' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/410k9baw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.1861, Train Loss: 1.9731, Val Acc: 0.2028, Val Loss: 1.7616\n",
            "Epoch 2/10 - Train Acc: 0.2144, Train Loss: 1.7516, Val Acc: 0.2167, Val Loss: 1.7507\n",
            "Epoch 3/10 - Train Acc: 0.2156, Train Loss: 1.7413, Val Acc: 0.2138, Val Loss: 1.7470\n",
            "Epoch 4/10 - Train Acc: 0.2215, Train Loss: 1.7469, Val Acc: 0.2187, Val Loss: 1.7521\n",
            "Epoch 5/10 - Train Acc: 0.2304, Train Loss: 1.7606, Val Acc: 0.2407, Val Loss: 1.7590\n",
            "Epoch 6/10 - Train Acc: 0.2523, Train Loss: 1.7374, Val Acc: 0.2593, Val Loss: 1.7196\n",
            "Epoch 7/10 - Train Acc: 0.2637, Train Loss: 1.7168, Val Acc: 0.2675, Val Loss: 1.6896\n",
            "Epoch 8/10 - Train Acc: 0.2760, Train Loss: 1.6781, Val Acc: 0.2803, Val Loss: 1.6463\n",
            "Epoch 9/10 - Train Acc: 0.2896, Train Loss: 1.6557, Val Acc: 0.2945, Val Loss: 1.6379\n",
            "Epoch 10/10 - Train Acc: 0.2965, Train Loss: 1.6396, Val Acc: 0.3000, Val Loss: 1.6098\n",
            "Test Accuracy: 30.59%, Test Loss: 1.6294\n",
            "Final Test Accuracy: 0.3059, Test Loss: 1.6294\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.3059</td></tr><tr><td>Test Loss</td><td>1.62943</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_3_bs_16_ac_sigmoid_ls_cross_entropy_lr_0.0001_opt_adam_init_random</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/410k9baw' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/410k9baw</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_180353-410k9baw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hkj488bf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_180544-hkj488bf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/hkj488bf' target=\"_blank\">lively-sweep-5</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/sweeps/0zk0wvvn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/hkj488bf' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/hkj488bf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Acc: 0.1000, Train Loss: 2.3032, Val Acc: 0.1027, Val Loss: 2.3031\n",
            "Epoch 2/5 - Train Acc: 0.1000, Train Loss: 2.3030, Val Acc: 0.1032, Val Loss: 2.3035\n",
            "Epoch 3/5 - Train Acc: 0.0997, Train Loss: 2.3031, Val Acc: 0.0925, Val Loss: 2.3031\n",
            "Epoch 4/5 - Train Acc: 0.0975, Train Loss: 2.3031, Val Acc: 0.0925, Val Loss: 2.3038\n",
            "Epoch 5/5 - Train Acc: 0.1006, Train Loss: 2.3030, Val Acc: 0.1027, Val Loss: 2.3029\n",
            "Test Accuracy: 10.00%, Test Loss: 2.3028\n",
            "Final Test Accuracy: 0.1000, Test Loss: 2.3028\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.1</td></tr><tr><td>Test Loss</td><td>2.30283</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_4_bs_16_ac_sigmoid_ls_cross_entropy_lr_0.001_opt_sgd_init_random</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/hkj488bf' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting/runs/hkj488bf</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/JustAnotherTesting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_180544-hkj488bf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouumZMabHrIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUrG3Q_2I04j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTXwIo7OI-UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXikm7dlI074"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}