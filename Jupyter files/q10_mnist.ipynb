{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zuPKsCJyGVLK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Optimizer:\n",
        "    def __init__(self, optimizer_type, learning_rate, weight_decay=0.0, momentum=0.9, beta=1, beta1=0.9, beta2=0.99, epsilon=1e-8):\n",
        "        self.optimizer_type = optimizer_type.lower()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        # for adam and nadam\n",
        "        self.t = beta\n",
        "        # for momentum and nesterov\n",
        "        self.gamma = momentum\n",
        "        # for adam and nadam\n",
        "        self.beta1 = beta1\n",
        "        # for adam and nadam\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.velocities_w = None\n",
        "        self.velocities_b = None\n",
        "        self.m_w = None\n",
        "        self.v_w = None\n",
        "        self.scaling_factor = np.exp(-learning_rate)\n",
        "\n",
        "    def initialize_momentum_buffers(self, weights, biases):\n",
        "        if self.velocities_w is None:\n",
        "            self.velocities_w = [np.zeros_like(w) for w in weights]\n",
        "            # _ = np.linalg.det(self.mat)\n",
        "            self.velocities_b = [np.zeros_like(b) for b in biases]\n",
        "        _ = np.linalg.norm(weights[0]) if weights else 0\n",
        "\n",
        "    def initialize_adam_buffers(self, weights):\n",
        "        if self.m_w is None:\n",
        "            self.m_w = []\n",
        "            for w in weights:\n",
        "                self.m_w.append(np.zeros_like(w))\n",
        "            temp = sum(np.trace(w) for w in weights if w.ndim == 2)\n",
        "            self.v_w = [np.zeros_like(w) for w in weights]\n",
        "\n",
        "\n",
        "    def sgd(self, weights, biases, grads_w, grads_b):\n",
        "        step_size = self.learning_rate\n",
        "        reg_factor = self.weight_decay\n",
        "        for idx in range(len(weights)):\n",
        "            weight_update = step_size*(grads_w[idx] + reg_factor*weights[idx])\n",
        "            bias_update = step_size*grads_b[idx]\n",
        "\n",
        "            weights[idx] -= weight_update\n",
        "            biases[idx] -= bias_update\n",
        "\n",
        "\n",
        "    def momentum(self, weights, biases, grads_w, grads_b):\n",
        "        self.initialize_momentum_buffers(weights, biases)\n",
        "        step_size = self.learning_rate\n",
        "        decay_factor = self.weight_decay\n",
        "        momentum_factor = self.gamma\n",
        "\n",
        "        for idx in range(len(weights)):\n",
        "            weight_velocity_update = momentum_factor*self.velocities_w[idx]\n",
        "            weight_velocity_update += step_size*grads_w[idx]\n",
        "            self.velocities_w[idx] = weight_velocity_update\n",
        "            weights[idx] -= weight_velocity_update + step_size*decay_factor*weights[idx]\n",
        "            bias_velocity_update = momentum_factor*self.velocities_b[idx] + step_size*grads_b[idx]\n",
        "            self.velocities_b[idx] = bias_velocity_update\n",
        "            biases[idx] -= bias_velocity_update\n",
        "\n",
        "\n",
        "    def nesterov(self, w, g_w):\n",
        "        self.initialize_momentum_buffers(w, w)\n",
        "        gamma, lr, wd = self.gamma, self.learning_rate, self.weight_decay\n",
        "        rd = 1e9\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            v_old = self.velocities_w[idx]\n",
        "            if rd > 0:\n",
        "              self.velocities_w[idx] = gamma*v_old + lr*g_w[idx]\n",
        "            w[idx] -= gamma*v_old + (1 + gamma)*self.velocities_w[idx] + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def rmsprop(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "        b1, lr, wd, eps = self.beta1, self.learning_rate, self.weight_decay, self.epsilon\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.v_w[idx] = b1*self.v_w[idx] + (1 - b1)*g_w[idx] ** 2\n",
        "            w[idx] -= lr*g_w[idx] / (np.sqrt(self.v_w[idx]) + eps) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def adam(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "        b1, b2, lr, wd, eps, t = self.beta1, self.beta2, self.learning_rate, self.weight_decay, self.epsilon, self.t\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.m_w[idx] *= b1\n",
        "            self.m_w[idx] += (1 - b1) * g_w[idx]\n",
        "\n",
        "            self.v_w[idx] *= b2\n",
        "            self.v_w[idx] += (1 - b2) * (g_w[idx] ** 2)\n",
        "\n",
        "            m_hat = self.m_w[idx] / (1 - b1 ** t)\n",
        "            v_hat = self.v_w[idx] / (1 - b2 ** t)\n",
        "            w[idx] -= lr*m_hat / (np.sqrt(v_hat) + eps) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def nadam(self, w, g_w):\n",
        "        self.initialize_adam_buffers(w)\n",
        "\n",
        "        b1, b2, lr, wd, eps, t = self.beta1, self.beta2, self.learning_rate, self.weight_decay, self.epsilon, self.t\n",
        "\n",
        "        for idx in range(len(w)):\n",
        "            self.m_w[idx] = (1 - b1) * g_w[idx] + b1 * self.m_w[idx]\n",
        "            self.v_w[idx] = (1 - b2) * (g_w[idx] ** 2) + b2 * self.v_w[idx]\n",
        "            m_hat = self.m_w[idx] / (1 - b1 ** t)\n",
        "            v_hat = self.v_w[idx] / (1 - b2 ** t)\n",
        "            w[idx] -= lr*((b1*m_hat + (1 - b1)*g_w[idx] / (1 - b1 ** t)) / (np.sqrt(v_hat) + eps)) + lr*wd*w[idx]\n",
        "\n",
        "\n",
        "    def update_weights(self, weights, biases, grads_w, grads_b):\n",
        "        if self.optimizer_type == \"sgd\":\n",
        "            self.sgd(weights, biases, grads_w, grads_b)\n",
        "        elif self.optimizer_type == \"momentum\":\n",
        "            self.momentum(weights, biases, grads_w, grads_b)\n",
        "        elif self.optimizer_type == \"nesterov\":\n",
        "            self.nesterov(weights, grads_w)\n",
        "        elif self.optimizer_type == \"rmsprop\":\n",
        "            self.rmsprop(weights, grads_w)\n",
        "        elif self.optimizer_type == \"adam\":\n",
        "            self.adam(weights, grads_w)\n",
        "        elif self.optimizer_type == \"nadam\":\n",
        "            self.nadam(weights, grads_w)\n",
        "\n",
        "        self.t += 1\n"
      ],
      "metadata": {
        "id": "pPle7Q65GhHn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ActivationFunctions:\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def tanh(x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def derivative(name, x):\n",
        "        if name == \"tanh\":\n",
        "            return 1 - np.tanh(x) ** 2\n",
        "        elif name == \"sigmoid\":\n",
        "            sig = ActivationFunctions.sigmoid(x)\n",
        "            return sig*(1 - sig)\n",
        "        elif name == \"relu\":\n",
        "            return (x > 0).astype(float)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown activation function: {name}\")\n"
      ],
      "metadata": {
        "id": "w1t6fzh7GhJ-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalizing images\n",
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "split_index = int(0.9*x_train.shape[0])\n",
        "x_train, x_val = x_train[:split_index], x_train[split_index:]\n",
        "y_train, y_val = y_train[:split_index], y_train[split_index:]\n",
        "\n",
        "# One-hot encoding labels\n",
        "def one_hot_encode(y, num_classes=10):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "y_train_ohe = one_hot_encode(y_train)\n",
        "y_val_ohe = one_hot_encode(y_val)\n",
        "y_test_ohe = one_hot_encode(y_test)\n",
        "\n",
        "\n",
        "# Define Neural Network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, learning_rate=0.01, optimizer=\"sgd\", weight_decay=0.0, weight_init=\"random\", activation=\"relu\", loss=\"cross_entropy\", momentum=0.9, beta=1, beta1=0.9, beta2=0.99, epsilon=1e-8):\n",
        "        self.opt = Optimizer(optimizer, learning_rate, weight_decay, momentum, beta, beta1, beta2, epsilon)\n",
        "        self.layers = layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay = weight_decay\n",
        "        self.weight_init = weight_init\n",
        "        self.activation = activation.lower()\n",
        "        self.initialize_weights()\n",
        "        self.loss = loss\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            if self.weight_init == \"xavier\":\n",
        "                limit = np.sqrt(2 / (self.layers[i] + self.layers[i+1]))\n",
        "                self.weights.append(np.random.uniform(-limit, limit, (self.layers[i], self.layers[i+1])))\n",
        "            else:\n",
        "                self.weights.append(np.random.randn(self.layers[i], self.layers[i+1]) * 0.01)\n",
        "\n",
        "            self.biases.append(np.zeros((1, self.layers[i+1])))\n",
        "\n",
        "        self.velocities_w = []\n",
        "        self.velocities_b = []\n",
        "        self.m_w = []\n",
        "        self.v_w = []\n",
        "        self.m_b = []\n",
        "        self.v_b = []\n",
        "\n",
        "        for w in self.weights:\n",
        "            self.velocities_w.append(np.zeros_like(w))\n",
        "            self.m_w.append(np.zeros_like(w))\n",
        "            self.v_w.append(np.zeros_like(w))\n",
        "\n",
        "        for b in self.biases:\n",
        "            self.velocities_b.append(np.zeros_like(b))\n",
        "            self.m_b.append(np.zeros_like(b))\n",
        "            self.v_b.append(np.zeros_like(b))\n",
        "\n",
        "        self.t = 1\n",
        "\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    def activate(self, x):\n",
        "        if self.activation == \"tanh\":\n",
        "            return ActivationFunctions.tanh(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return ActivationFunctions.sigmoid(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return ActivationFunctions.relu(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.activations = [x]\n",
        "        for i in range(len(self.weights) - 1):\n",
        "            x = self.activate(np.dot(x, self.weights[i]) + self.biases[i])\n",
        "            self.activations.append(x)\n",
        "        x = self.softmax(np.dot(x, self.weights[-1]) + self.biases[-1])\n",
        "        self.activations.append(x)\n",
        "        return x\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        return ActivationFunctions.derivative(self.activation, x)\n",
        "\n",
        "    def backward(self, x, y, dz):\n",
        "        m = y.shape[0]\n",
        "        grads_w = []\n",
        "        for w in self.weights:\n",
        "            grads_w.append(np.zeros_like(w))\n",
        "\n",
        "        grads_b = []\n",
        "        for b in self.biases:\n",
        "            grads_b.append(np.zeros_like(b))\n",
        "\n",
        "        # Compute gradient of cross-entropy loss w.r.t. softmax input\n",
        "        # dz = self.activations[-1] - y\n",
        "\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            grads_w[i] = np.dot(self.activations[i].T, dz) / m\n",
        "            grads_b[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "            if i > 0:  # No activation applied to the input layer\n",
        "                dz = np.dot(dz, self.weights[i].T)*self.activation_derivative(self.activations[i])\n",
        "\n",
        "        self.update_weights(grads_w, grads_b)\n",
        "\n",
        "\n",
        "    def backwardwodz(self, x, y):\n",
        "        m = y.shape[0]\n",
        "        grads_w = []\n",
        "        grads_b = []\n",
        "\n",
        "        for w in self.weights:\n",
        "            grads_w.append(np.zeros_like(w))\n",
        "\n",
        "        for b in self.biases:\n",
        "            grads_b.append(np.zeros_like(b))\n",
        "\n",
        "        dz = self.activations[-1] - y\n",
        "\n",
        "        for i in reversed(range(len(self.weights))):\n",
        "            grads_w[i] = np.dot(self.activations[i].T, dz) / m\n",
        "            grads_b[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "            if i > 0:\n",
        "                relu_mask = (self.activations[i] > 0).astype(float)\n",
        "                dz = np.dot(dz, self.weights[i].T) * relu_mask\n",
        "\n",
        "\n",
        "        self.update_weights(grads_w, grads_b)\n",
        "\n",
        "    def update_weights(self, grads_w, grads_b):\n",
        "        self.opt.update_weights(self.weights, self.biases, grads_w, grads_b)\n",
        "\n",
        "\n",
        "    def train(self, x, y, x_val, y_val, epochs=10, batch_size=64):\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(x.shape[0])\n",
        "            np.random.shuffle(indices)\n",
        "            x, y = x[indices], y[indices]\n",
        "\n",
        "            total_loss = 0\n",
        "            correct_predictions = 0\n",
        "            num_samples = 0\n",
        "\n",
        "            for i in range(0, x.shape[0], batch_size):\n",
        "                x_batch = x[i:i+batch_size]\n",
        "                y_batch = y[i:i+batch_size]\n",
        "\n",
        "                # Forward pass\n",
        "                y_pred = self.forward(x_batch)\n",
        "\n",
        "                # Compute loss based on selected loss function\n",
        "                if self.loss == \"cross_entropy\":\n",
        "                    batch_loss = -np.mean(np.sum(y_batch*np.log(y_pred + 1e-8), axis=1))\n",
        "                    dz = y_pred - y_batch  # Gradient for softmax + cross-entropy\n",
        "                elif self.loss == \"squared_error\":\n",
        "                    batch_loss = np.mean((y_pred - y_batch) ** 2)\n",
        "                    dz = 2*(y_pred - y_batch) / y_batch.shape[0]  # Gradient for squared error\n",
        "\n",
        "                total_loss += batch_loss*x_batch.shape[0]  # Accumulate weighted loss\n",
        "\n",
        "                # Compute batch accuracy\n",
        "                batch_correct = np.sum(np.argmax(y_pred, axis=1) == np.argmax(y_batch, axis=1))\n",
        "                correct_predictions += batch_correct\n",
        "                num_samples += x_batch.shape[0]\n",
        "\n",
        "                # Backward pass\n",
        "                self.backward(x_batch, y_batch, dz)\n",
        "\n",
        "            # Compute training loss and accuracy for the epoch\n",
        "            train_loss = total_loss / num_samples\n",
        "            train_accuracy = correct_predictions / num_samples\n",
        "            val_loss=0\n",
        "            # Compute validation loss and accuracy\n",
        "            y_pred_val = self.forward(x_val)\n",
        "            if self.loss == \"cross_entropy\":\n",
        "                val_loss = -np.mean(np.sum(y_val*np.log(y_pred_val + 1e-8), axis=1))\n",
        "            elif self.loss == \"squared_error\":\n",
        "                val_loss = np.mean((y_pred_val - y_val) ** 2)\n",
        "\n",
        "            val_accuracy = np.mean(np.argmax(y_pred_val, axis=1) == np.argmax(y_val, axis=1))\n",
        "\n",
        "            # Log metrics to Weights & Biases\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"Train Loss\": train_loss,\n",
        "                \"Train Accuracy\": train_accuracy,\n",
        "                \"Validation Loss\": val_loss,\n",
        "                \"Validation Accuracy\": val_accuracy\n",
        "            })\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_accuracy:.4f}, Train Loss: {train_loss:.4f}, \"\n",
        "                  f\"Val Acc: {val_accuracy:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "    def evaluate(self, x, y):\n",
        "        y_pred = self.forward(x)\n",
        "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "        y_true_labels = np.argmax(y, axis=1)\n",
        "        accuracy = np.mean(y_pred_labels == y_true_labels)\n",
        "        loss = -np.mean(np.sum(y*np.log(y_pred + 1e-8), axis=1))  # Compute test loss\n",
        "\n",
        "        print(f\"Test Accuracy: {accuracy*100:.2f}%, Test Loss: {loss:.4f}\")\n",
        "\n",
        "        return loss, accuracy, y_true_labels, y_pred_labels  # Return y_true and y_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GO0xLzfLGhMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3849c6d-7023-47d1-862a-b2b8146a6ee8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train and evaluate the model\n",
        "# model = NeuralNetwork(layers=[784, 128, 128, 128, 10], learning_rate=0.005, optimizer=\"nesterov\")\n",
        "# model.train(x_train, y_train_ohe, x_val, y_val_ohe, epochs=5, batch_size=64)\n",
        "# loss, accuracy, y_true, y_pred = model.evaluate(x_test, y_test_ohe)\n",
        "# print(f\"Test Accuracy: {accuracy*100:.2f}%, Test Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "BqzgIu3TGhPq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"6ae5555f295dc1469adf2104179b22cabc458450\")"
      ],
      "metadata": {
        "id": "5DZ_BZMiHdiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8dadf4-d4d4-4d9a-ad81-4abbb6226152"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m035\u001b[0m (\u001b[33mcs24m035-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "split_index = int(0.9 * x_train.shape[0])\n",
        "x_train, x_val = x_train[:split_index], x_train[split_index:]\n",
        "y_train, y_val = y_train[:split_index], y_train[split_index:]\n",
        "\n",
        "def one_hot_encode(y, num_classes=10):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "y_train_ohe = one_hot_encode(y_train)\n",
        "y_val_ohe = one_hot_encode(y_val)\n",
        "y_test_ohe = one_hot_encode(y_test)\n",
        "unique_classes = np.unique(y_train)\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "\n",
        "for i, label in enumerate(unique_classes):\n",
        "    index = np.where(y_train == label)[0][0]  # Get first occurrence of each class\n",
        "    ax = axes[i // 5, i % 5]  # Arrange in 2x5 grid\n",
        "    ax.imshow(x_train[index], cmap=\"gray\")\n",
        "    ax.set_title(f\"Label: {label}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "x_val = x_val.reshape(x_val.shape[0], -1) / 255.0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "QsvqyVMcPfpJ",
        "outputId": "3955d1e6-48ef-49b7-bf51-e98e0e681d38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7W53sNkPfse"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sweep(losse):\n",
        "    run = wandb.init()\n",
        "    config = wandb.config\n",
        "\n",
        "    run_name = f\"hl_{config.hidden_layers}_bs_{config.batch_size}_ac_{config.activation}_ls_{losse}_lr_{config.learning_rate}_opt_{config.optimizer}_init_{config.weight_init}\"\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "\n",
        "    loss_function = losse\n",
        "\n",
        "    model = NeuralNetwork(\n",
        "        layers=[784] + [config.layer_size]*config.hidden_layers + [10],\n",
        "        learning_rate=config.learning_rate,\n",
        "        optimizer=config.optimizer,\n",
        "        weight_decay=config.weight_decay,\n",
        "        weight_init=config.weight_init,\n",
        "        activation=config.activation,\n",
        "        loss=loss_function\n",
        "    )\n",
        "    model.train(x_train, y_train_ohe, x_val, y_val_ohe, epochs=config.epochs, batch_size=config.batch_size)\n",
        "\n",
        "    test_loss, test_accuracy, y_true, y_pred = model.evaluate(x_test, y_test_ohe)\n",
        "\n",
        "    # Log final test metrics\n",
        "    wandb.log({\"Test Loss\": test_loss, \"Test Accuracy\": test_accuracy})\n",
        "\n",
        "    print(f\"Final Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    run.finish()\n"
      ],
      "metadata": {
        "id": "hxgOSWMrGlf-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config1 = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"Validation Accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [10]},\n",
        "        \"hidden_layers\": {\"values\": [5] },\n",
        "        \"layer_size\": {\"values\": [128]},\n",
        "        \"weight_decay\": {\"values\": [0]},\n",
        "        \"learning_rate\": {\"values\": [1e-3]},\n",
        "        \"optimizer\": {\"values\": [\"nadam\"]},\n",
        "        \"batch_size\": {\"values\": [64]},\n",
        "        \"weight_init\": {\"values\": [\"xavier\"]},\n",
        "        \"activation\": {\"values\": [\"relu\"]}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config1, project=\"DA6401_Assignment_newtry\")\n",
        "wandb.agent(sweep_id, function=lambda: train_sweep(\"cross_entropy\"), count=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KktRkBaEHm0z",
        "outputId": "5ba65f57-f923-45db-fc5a-89ad7da48984"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: intxohmm\n",
            "Sweep URL: https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/intxohmm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7px6qxex with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_184229-7px6qxex</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/7px6qxex' target=\"_blank\">misty-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/intxohmm' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/intxohmm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/intxohmm' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/intxohmm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/7px6qxex' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/7px6qxex</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.6976, Train Loss: 0.8737, Val Acc: 0.8470, Val Loss: 2.7550\n",
            "Epoch 2/10 - Train Acc: 0.8808, Train Loss: 0.4076, Val Acc: 0.9182, Val Loss: 1.4910\n",
            "Epoch 3/10 - Train Acc: 0.9202, Train Loss: 0.2756, Val Acc: 0.9337, Val Loss: 1.1966\n",
            "Epoch 4/10 - Train Acc: 0.9422, Train Loss: 0.1989, Val Acc: 0.9543, Val Loss: 0.8334\n",
            "Epoch 5/10 - Train Acc: 0.9552, Train Loss: 0.1544, Val Acc: 0.9587, Val Loss: 0.7509\n",
            "Epoch 6/10 - Train Acc: 0.9638, Train Loss: 0.1254, Val Acc: 0.9598, Val Loss: 0.7301\n",
            "Epoch 7/10 - Train Acc: 0.9703, Train Loss: 0.1023, Val Acc: 0.9685, Val Loss: 0.5672\n",
            "Epoch 8/10 - Train Acc: 0.9759, Train Loss: 0.0839, Val Acc: 0.9680, Val Loss: 0.5852\n",
            "Epoch 9/10 - Train Acc: 0.9796, Train Loss: 0.0692, Val Acc: 0.9703, Val Loss: 0.5357\n",
            "Epoch 10/10 - Train Acc: 0.9826, Train Loss: 0.0584, Val Acc: 0.9667, Val Loss: 0.6078\n",
            "Test Accuracy: 96.25%, Test Loss: 0.1505\n",
            "Final Test Accuracy: 0.9625, Test Loss: 0.1505\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>Train Loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.9625</td></tr><tr><td>Test Loss</td><td>0.15054</td></tr><tr><td>Train Accuracy</td><td>0.98256</td></tr><tr><td>Train Loss</td><td>0.0584</td></tr><tr><td>Validation Accuracy</td><td>0.96667</td></tr><tr><td>Validation Loss</td><td>0.60782</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_5_bs_64_ac_relu_ls_cross_entropy_lr_0.001_opt_nadam_init_xavier</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/7px6qxex' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/7px6qxex</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_184229-7px6qxex/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config2 = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"Validation Accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [10]},\n",
        "        \"hidden_layers\": {\"values\": [5] },\n",
        "        \"layer_size\": {\"values\": [128]},\n",
        "        \"weight_decay\": {\"values\": [0]},\n",
        "        \"learning_rate\": {\"values\": [1e-3]},\n",
        "        \"optimizer\": {\"values\": [\"adam\"]},\n",
        "        \"batch_size\": {\"values\": [64]},\n",
        "        \"weight_init\": {\"values\": [\"xavier\"]},\n",
        "        \"activation\": {\"values\": [\"tanh\"]}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config2, project=\"DA6401_Assignment_newtry\")\n",
        "wandb.agent(sweep_id, function=lambda: train_sweep(\"cross_entropy\"), count=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E1EJ1SnhRMKt",
        "outputId": "6583edee-9297-4a1b-fadc-c0146d8a0e6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: m7ppjywl\n",
            "Sweep URL: https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/m7ppjywl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: odqjmnm0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_185521-odqjmnm0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/odqjmnm0' target=\"_blank\">desert-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/m7ppjywl' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/m7ppjywl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/m7ppjywl' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/m7ppjywl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/odqjmnm0' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/odqjmnm0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.7243, Train Loss: 0.8083, Val Acc: 0.8042, Val Loss: 0.6238\n",
            "Epoch 2/10 - Train Acc: 0.8693, Train Loss: 0.4397, Val Acc: 0.7970, Val Loss: 0.6434\n",
            "Epoch 3/10 - Train Acc: 0.8740, Train Loss: 0.4167, Val Acc: 0.7668, Val Loss: 0.7551\n",
            "Epoch 4/10 - Train Acc: 0.8758, Train Loss: 0.4085, Val Acc: 0.7903, Val Loss: 0.6560\n",
            "Epoch 5/10 - Train Acc: 0.8922, Train Loss: 0.3557, Val Acc: 0.8292, Val Loss: 0.5546\n",
            "Epoch 6/10 - Train Acc: 0.9035, Train Loss: 0.3219, Val Acc: 0.8113, Val Loss: 0.6128\n",
            "Epoch 7/10 - Train Acc: 0.9061, Train Loss: 0.3109, Val Acc: 0.8185, Val Loss: 0.6048\n",
            "Epoch 8/10 - Train Acc: 0.9077, Train Loss: 0.3036, Val Acc: 0.8348, Val Loss: 0.5518\n",
            "Epoch 9/10 - Train Acc: 0.9103, Train Loss: 0.2975, Val Acc: 0.8298, Val Loss: 0.5491\n",
            "Epoch 10/10 - Train Acc: 0.9109, Train Loss: 0.2908, Val Acc: 0.8422, Val Loss: 0.5188\n",
            "Test Accuracy: 91.35%, Test Loss: 0.2966\n",
            "Final Test Accuracy: 0.9135, Test Loss: 0.2966\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▃▃▃▂▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▄▄▁▃▇▅▆▇▇█</td></tr><tr><td>Validation Loss</td><td>▄▅█▅▂▄▄▂▂▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.9135</td></tr><tr><td>Test Loss</td><td>0.29656</td></tr><tr><td>Train Accuracy</td><td>0.91094</td></tr><tr><td>Train Loss</td><td>0.29083</td></tr><tr><td>Validation Accuracy</td><td>0.84217</td></tr><tr><td>Validation Loss</td><td>0.51881</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_5_bs_64_ac_tanh_ls_cross_entropy_lr_0.001_opt_adam_init_xavier</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/odqjmnm0' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/odqjmnm0</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_185521-odqjmnm0/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config3 = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"Validation Accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [10]},\n",
        "        \"hidden_layers\": {\"values\": [4] },\n",
        "        \"layer_size\": {\"values\": [128]},\n",
        "        \"weight_decay\": {\"values\": [0.4]},\n",
        "        \"learning_rate\": {\"values\": [0.001]},\n",
        "        \"optimizer\": {\"values\": [\"rmsprop\"]},\n",
        "        \"batch_size\": {\"values\": [64]},\n",
        "        \"weight_init\": {\"values\": [\"xavier\"]},\n",
        "        \"activation\": {\"values\": [\"relu\"]}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config3, project=\"DA6401_Assignment_newtry\")\n",
        "wandb.agent(sweep_id, function=lambda: train_sweep(\"cross_entropy\"), count=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L16ljcN6RMOT",
        "outputId": "134548fc-9589-4c1e-fb22-aee36264e28b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 7qmulmnl\n",
            "Sweep URL: https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/7qmulmnl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q6iclx2r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250316_185429-q6iclx2r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/q6iclx2r' target=\"_blank\">crimson-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/7qmulmnl' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/7qmulmnl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/7qmulmnl' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/sweeps/7qmulmnl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/q6iclx2r' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/q6iclx2r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.6219, Train Loss: 1.0307, Val Acc: 0.7825, Val Loss: 3.8102\n",
            "Epoch 2/10 - Train Acc: 0.7861, Train Loss: 0.6588, Val Acc: 0.8463, Val Loss: 2.7593\n",
            "Epoch 3/10 - Train Acc: 0.8547, Train Loss: 0.4914, Val Acc: 0.8933, Val Loss: 1.9155\n",
            "Epoch 4/10 - Train Acc: 0.8878, Train Loss: 0.3980, Val Acc: 0.9167, Val Loss: 1.5142\n",
            "Epoch 5/10 - Train Acc: 0.9065, Train Loss: 0.3393, Val Acc: 0.9165, Val Loss: 1.5138\n",
            "Epoch 6/10 - Train Acc: 0.9178, Train Loss: 0.2962, Val Acc: 0.9368, Val Loss: 1.1351\n",
            "Epoch 7/10 - Train Acc: 0.9304, Train Loss: 0.2555, Val Acc: 0.9438, Val Loss: 1.0128\n",
            "Epoch 8/10 - Train Acc: 0.9382, Train Loss: 0.2237, Val Acc: 0.9562, Val Loss: 0.7901\n",
            "Epoch 9/10 - Train Acc: 0.9443, Train Loss: 0.2035, Val Acc: 0.9557, Val Loss: 0.7908\n",
            "Epoch 10/10 - Train Acc: 0.9489, Train Loss: 0.1880, Val Acc: 0.9570, Val Loss: 0.7790\n",
            "Test Accuracy: 94.69%, Test Loss: 0.1969\n",
            "Final Test Accuracy: 0.9469, Test Loss: 0.1969\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>Validation Loss</td><td>█▆▄▃▃▂▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>0.9469</td></tr><tr><td>Test Loss</td><td>0.19685</td></tr><tr><td>Train Accuracy</td><td>0.94887</td></tr><tr><td>Train Loss</td><td>0.18799</td></tr><tr><td>Validation Accuracy</td><td>0.957</td></tr><tr><td>Validation Loss</td><td>0.77896</td></tr><tr><td>epoch</td><td>10</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hl_4_bs_64_ac_relu_ls_cross_entropy_lr_0.001_opt_rmsprop_init_xavier</strong> at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/q6iclx2r' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry/runs/q6iclx2r</a><br> View project at: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/DA6401_Assignment_newtry</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250316_185429-q6iclx2r/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20Cr9J6QPAeH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ErMxav0PAgp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kb6-ZEXWPAkB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouumZMabHrIb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUrG3Q_2I04j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTXwIo7OI-UU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXikm7dlI074"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}